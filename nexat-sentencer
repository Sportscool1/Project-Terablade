from transformers import AutoModelForCausalLM, AutoTokenizer, TextGenerationPipeline

def prompt():
    # Load the DialoGPT model and tokenizer
    model_name = "microsoft/DialoGPT-small"
    model = AutoModelForCausalLM.from_pretrained(model_name)
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    # Create a text generation pipeline
    chatbot = TextGenerationPipeline(model=model, tokenizer=tokenizer)
    TF_ENABLE_ONEDNN_OPTS=0

    # Start a conversation loop
    print("nexat-sentencer is designed to finish your prompts using the nexat-diablo architecture.")
    print("(nexat-sentencer assumes that the universe is reddit)")

    last_role = None  # Variable to store the last role in the conversation
    topic_prompt = "Discuss"  # Initial topic prompt

    while True:
        # Get user input
        user_input = input("You: ")

        # Exit the conversation if the user types 'exit'
        if user_input.lower() == 'exit':
            print("Chatbot: Goodbye!")
            break

        # Determine the role based on the last role
        role = "User:" if last_role != "User:" else "NEXAT:"

        # Generate a response using the text generation pipeline
        full_input = f"{role} {topic_prompt} {user_input}" if last_role == "User:" else f"{role} {user_input}"
        response = chatbot(full_input, max_length=5000, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95, temperature=0.7, do_sample=True)[0]['generated_text']

        # Extract and print the bot response
        response_parts = response.split(f"{role} ", 1)
        response = response_parts[1] if len(response_parts) > 1 and response_parts[1] != user_input else response
        print(f"NEXAT: {response}")

        # Update the last role
        last_role = "NEXAT:"

if __name__ == "__main__":
    prompt()
